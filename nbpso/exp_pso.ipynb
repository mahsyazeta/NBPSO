{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB, GaussianNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import issparse\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('text_preprocessing/final_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert sentiment labels to binary\n",
    "def convert_label_sentimen(label_sentimen):\n",
    "    return 1 if label_sentimen == \"positive\" else 0\n",
    "\n",
    "df['label_sentimen'] = df['Sentiment'].apply(convert_label_sentimen)\n",
    "df.drop(df.columns[[0]], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= df['tweet_tokens_stemmed'] \n",
    "y= df['label_sentimen']\n",
    "# k-fold cross-validation\n",
    "kfold = StratifiedKFold(n_splits=10, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes:\n",
    "    def __init__(self, model_class):\n",
    "        self.model_class = model_class\n",
    "        self.clf = None\n",
    "    \n",
    "    def fit(self, X_train, y_train, selected_features):\n",
    "        self.clf = self.model_class()\n",
    "        if issparse(X_train):\n",
    "            X_train = X_train.toarray()\n",
    "        self.clf.fit(X_train[:, selected_features], y_train)\n",
    "    \n",
    "    def predict(self, X_test, selected_features):\n",
    "        if self.clf is None:\n",
    "            raise ValueError(\"Classifier not fitted. Please call 'fit' method first.\")\n",
    "        if issparse(X_test):\n",
    "            X_test = X_test.toarray()\n",
    "        return self.clf.predict(X_test[:, selected_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_features(X_train, y_train, selected_features, classifier):\n",
    "    clf = classifier\n",
    "    cv_results = cross_val_score(clf.clf, X_train[:, selected_features], y_train, cv=kfold, scoring='accuracy')\n",
    "    return cv_results.mean()\n",
    "\n",
    "def pso_feature_selection(X_train, y_train, n_particles, inertia, global_weight, local_weight, model_class, tol=1e-5, patience=10):\n",
    "    num_samples, num_features = X_train.shape\n",
    "    bounds = [0, 1]\n",
    "    \n",
    "    num_particles = n_particles\n",
    "    dimensions = num_features\n",
    "    particles = np.random.rand(num_particles, dimensions)\n",
    "    velocities = np.random.rand(num_particles, dimensions) * 0.1\n",
    "    best_positions = particles.copy()\n",
    "    best_scores = np.zeros(num_particles)\n",
    "\n",
    "    global_best_position = np.zeros(dimensions)\n",
    "    global_best_score = 0\n",
    "\n",
    "    no_improvement_count = 0\n",
    "    previous_global_best_score = 0\n",
    "\n",
    "    while no_improvement_count < patience:\n",
    "        for particle in range(num_particles):\n",
    "            r1 = np.random.rand(dimensions)\n",
    "            r2 = np.random.rand(dimensions)\n",
    "            velocities[particle] = (inertia * velocities[particle] +\n",
    "                                    global_weight * r1 * (best_positions[particle] - particles[particle]) +\n",
    "                                    local_weight * r2 * (global_best_position - particles[particle]))\n",
    "\n",
    "            particles[particle] += velocities[particle]\n",
    "            particles[particle] = np.clip(particles[particle], bounds[0], bounds[1])\n",
    "\n",
    "            selected_features = particles[particle] > 0.5\n",
    "            nb = NaiveBayes(model_class)\n",
    "            nb.fit(X_train, y_train, selected_features)\n",
    "            accuracy = evaluate_features(X_train, y_train, selected_features, nb)\n",
    "\n",
    "            if accuracy > best_scores[particle]:\n",
    "                best_scores[particle] = accuracy\n",
    "                best_positions[particle] = particles[particle].copy()\n",
    "\n",
    "            if accuracy > global_best_score:\n",
    "                global_best_score = accuracy\n",
    "                global_best_position = particles[particle].copy()\n",
    "\n",
    "        if abs(global_best_score - previous_global_best_score) < tol:\n",
    "            no_improvement_count += 1\n",
    "        else:\n",
    "            no_improvement_count = 0\n",
    "        \n",
    "        previous_global_best_score = global_best_score\n",
    "\n",
    "    return global_best_position > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Model  Population Size  Average Accuracy  Average Precision  Average Recall\n",
      "MultinomialNB                5            0.7625           0.765507           0.770\n",
      "MultinomialNB               10            0.7725           0.748386           0.820\n",
      "MultinomialNB               20            0.7825           0.776865           0.800\n",
      "MultinomialNB               40            0.7775           0.756904           0.820\n",
      "MultinomialNB               80            0.7675           0.762152           0.785\n"
     ]
    }
   ],
   "source": [
    "# Define parameters for PSO optimization\n",
    "population_size_range = [5 * (2 ** i) for i in range(5)]  # 5, 10, 20\n",
    "inertia = 0.6\n",
    "global_weight = 0.3\n",
    "local_weight = 0.6\n",
    "\n",
    "results = []\n",
    "\n",
    "for n_particles in population_size_range:\n",
    "    accuracy_scores = []\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "\n",
    "    for train_idx, test_idx in kfold.split(X, y):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        tfidf_model = TfidfVectorizer(smooth_idf=False)\n",
    "        X_train_tfidf = tfidf_model.fit_transform(X_train)\n",
    "        X_test_tfidf = tfidf_model.transform(X_test)\n",
    "\n",
    "        X_train_dense = X_train_tfidf.toarray()\n",
    "        selected_features = pso_feature_selection(X_train_dense, y_train, n_particles, inertia, global_weight, local_weight, MultinomialNB)\n",
    "\n",
    "        if not np.any(selected_features):\n",
    "            selected_features[0] = True\n",
    "\n",
    "        nb = NaiveBayes(MultinomialNB)\n",
    "        nb.fit(X_train_tfidf, y_train, selected_features)\n",
    "        y_pred = nb.predict(X_test_tfidf.toarray(), selected_features)\n",
    "\n",
    "        accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
    "        precision_scores.append(precision_score(y_test, y_pred))\n",
    "        recall_scores.append(recall_score(y_test, y_pred))\n",
    "\n",
    "    fold_results = {\n",
    "        \"Model\": \"MultinomialNB\",\n",
    "        \"Population Size\": n_particles,\n",
    "        \"Average Accuracy\": np.mean(accuracy_scores),\n",
    "        \"Average Precision\": np.mean(precision_scores),\n",
    "        \"Average Recall\": np.mean(recall_scores)\n",
    "    }\n",
    "\n",
    "    results.append(fold_results)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values(by=[\"Population Size\", \"Average Accuracy\"], ascending=[True, False])\n",
    "\n",
    "print(results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Model  Inertia Weight  Average Accuracy  Average Precision  Average Recall\n",
      "MultinomialNB             0.1            0.7625           0.770838           0.755\n",
      "MultinomialNB             0.2            0.7500           0.741006           0.770\n",
      "MultinomialNB             0.3            0.7650           0.765899           0.780\n",
      "MultinomialNB             0.4            0.7700           0.776905           0.765\n",
      "MultinomialNB             0.5            0.7400           0.736531           0.765\n",
      "MultinomialNB             0.6            0.7675           0.762708           0.790\n",
      "MultinomialNB             0.7            0.7800           0.759373           0.820\n",
      "MultinomialNB             0.8            0.7950           0.767978           0.850\n",
      "MultinomialNB             0.9            0.7850           0.769700           0.815\n",
      "MultinomialNB             1.0            0.7625           0.737769           0.820\n"
     ]
    }
   ],
   "source": [
    "# Define parameters for PSO optimization\n",
    "n_particles = 20\n",
    "inertia_weight_range = np.linspace(0.1, 1, num=10)\n",
    "global_weight = 0.3\n",
    "local_weight = 0.6\n",
    "\n",
    "results = []\n",
    "\n",
    "for inertia in inertia_weight_range:\n",
    "    accuracy_scores = []\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "\n",
    "    for train_idx, test_idx in kfold.split(X, y):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        tfidf_model = TfidfVectorizer(smooth_idf=False)\n",
    "        X_train_tfidf = tfidf_model.fit_transform(X_train)\n",
    "        X_test_tfidf = tfidf_model.transform(X_test)\n",
    "\n",
    "        X_train_dense = X_train_tfidf.toarray()\n",
    "        selected_features = pso_feature_selection(X_train_dense, y_train, n_particles, inertia, global_weight, local_weight, MultinomialNB)\n",
    "\n",
    "        if not np.any(selected_features):\n",
    "            selected_features[0] = True\n",
    "\n",
    "        nb = NaiveBayes(MultinomialNB)\n",
    "        nb.fit(X_train_tfidf, y_train, selected_features)\n",
    "        y_pred = nb.predict(X_test_tfidf.toarray(), selected_features)\n",
    "\n",
    "        accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
    "        precision_scores.append(precision_score(y_test, y_pred))\n",
    "        recall_scores.append(recall_score(y_test, y_pred))\n",
    "\n",
    "    fold_results = {\n",
    "        \"Model\": \"MultinomialNB\",\n",
    "        \"Inertia Weight\": inertia,\n",
    "        \"Average Accuracy\": np.mean(accuracy_scores),\n",
    "        \"Average Precision\": np.mean(precision_scores),\n",
    "        \"Average Recall\": np.mean(recall_scores)\n",
    "    }\n",
    "\n",
    "    results.append(fold_results)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values(by=[\"Inertia Weight\", \"Average Accuracy\"], ascending=[True, False])\n",
    "\n",
    "print(results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Model  Global Best Weight  Average Accuracy  Average Precision  Average Recall\n",
      "MultinomialNB                 0.1            0.7925           0.784037           0.820\n",
      "MultinomialNB                 0.2            0.7650           0.748364           0.810\n",
      "MultinomialNB                 0.3            0.7700           0.747226           0.820\n",
      "MultinomialNB                 0.4            0.7725           0.761049           0.805\n",
      "MultinomialNB                 0.5            0.7675           0.740089           0.830\n",
      "MultinomialNB                 0.6            0.7700           0.741188           0.835\n",
      "MultinomialNB                 0.7            0.7800           0.753750           0.835\n",
      "MultinomialNB                 0.8            0.7700           0.749042           0.820\n",
      "MultinomialNB                 0.9            0.8000           0.779167           0.845\n",
      "MultinomialNB                 1.0            0.8025           0.781664           0.845\n"
     ]
    }
   ],
   "source": [
    "# Define parameters for PSO optimization\n",
    "n_particles = 20\n",
    "inertia_weight = 0.8\n",
    "global_best_weight_range = np.linspace(0.1, 1, num=10)\n",
    "local_weight = 0.6\n",
    "\n",
    "results = []\n",
    "\n",
    "for global_weight in global_best_weight_range:\n",
    "    accuracy_scores = []\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "\n",
    "    for train_idx, test_idx in kfold.split(X, y):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        tfidf_model = TfidfVectorizer(smooth_idf=False)\n",
    "        X_train_tfidf = tfidf_model.fit_transform(X_train)\n",
    "        X_test_tfidf = tfidf_model.transform(X_test)\n",
    "\n",
    "        X_train_dense = X_train_tfidf.toarray()\n",
    "        selected_features = pso_feature_selection(X_train_dense, y_train, n_particles, inertia, global_weight, local_weight, MultinomialNB)\n",
    "\n",
    "        if not np.any(selected_features):\n",
    "            selected_features[0] = True\n",
    "\n",
    "        nb = NaiveBayes(MultinomialNB)\n",
    "        nb.fit(X_train_tfidf, y_train, selected_features)\n",
    "        y_pred = nb.predict(X_test_tfidf.toarray(), selected_features)\n",
    "\n",
    "        accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
    "        precision_scores.append(precision_score(y_test, y_pred))\n",
    "        recall_scores.append(recall_score(y_test, y_pred))\n",
    "\n",
    "    fold_results = {\n",
    "        \"Model\": \"MultinomialNB\",\n",
    "        \"Global Best Weight\": global_weight,\n",
    "        \"Average Accuracy\": np.mean(accuracy_scores),\n",
    "        \"Average Precision\": np.mean(precision_scores),\n",
    "        \"Average Recall\": np.mean(recall_scores)\n",
    "    }\n",
    "\n",
    "    results.append(fold_results)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values(by=[\"Global Best Weight\", \"Average Accuracy\"], ascending=[True, False])\n",
    "\n",
    "print(results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Model  Local Best Weight  Average Accuracy  Average Precision  Average Recall\n",
      "MultinomialNB                0.1            0.7875           0.766974           0.835\n",
      "MultinomialNB                0.2            0.7600           0.745479           0.800\n",
      "MultinomialNB                0.3            0.7875           0.764493           0.835\n",
      "MultinomialNB                0.4            0.7750           0.753225           0.825\n",
      "MultinomialNB                0.5            0.7850           0.768351           0.820\n",
      "MultinomialNB                0.6            0.7700           0.750023           0.820\n",
      "MultinomialNB                0.7            0.7850           0.758932           0.840\n",
      "MultinomialNB                0.8            0.7900           0.771295           0.830\n",
      "MultinomialNB                0.9            0.7825           0.761840           0.830\n",
      "MultinomialNB                1.0            0.7850           0.766488           0.825\n"
     ]
    }
   ],
   "source": [
    "# Define parameters for PSO optimization\n",
    "n_particles = 20\n",
    "inertia_weight = 0.8\n",
    "global_weight = 0.3\n",
    "local_best_weight_range = np.linspace(0.1, 1, num=10)\n",
    "\n",
    "results = []\n",
    "\n",
    "for local_weight in local_best_weight_range:\n",
    "    accuracy_scores = []\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "\n",
    "    for train_idx, test_idx in kfold.split(X, y):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        tfidf_model = TfidfVectorizer(smooth_idf=False)\n",
    "        X_train_tfidf = tfidf_model.fit_transform(X_train)\n",
    "        X_test_tfidf = tfidf_model.transform(X_test)\n",
    "\n",
    "        X_train_dense = X_train_tfidf.toarray()\n",
    "        selected_features = pso_feature_selection(X_train_dense, y_train, n_particles, inertia, global_weight, local_weight, MultinomialNB)\n",
    "\n",
    "        if not np.any(selected_features):\n",
    "            selected_features[0] = True\n",
    "\n",
    "        nb = NaiveBayes(MultinomialNB)\n",
    "        nb.fit(X_train_tfidf, y_train, selected_features)\n",
    "        y_pred = nb.predict(X_test_tfidf.toarray(), selected_features)\n",
    "\n",
    "        accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
    "        precision_scores.append(precision_score(y_test, y_pred))\n",
    "        recall_scores.append(recall_score(y_test, y_pred))\n",
    "\n",
    "    fold_results = {\n",
    "        \"Model\": \"MultinomialNB\",\n",
    "        \"Local Best Weight\": local_weight,\n",
    "        \"Average Accuracy\": np.mean(accuracy_scores),\n",
    "        \"Average Precision\": np.mean(precision_scores),\n",
    "        \"Average Recall\": np.mean(recall_scores)\n",
    "    }\n",
    "\n",
    "    results.append(fold_results)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values(by=[\"Local Best Weight\", \"Average Accuracy\"], ascending=[True, False])\n",
    "\n",
    "print(results_df.to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
