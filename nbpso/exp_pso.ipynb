{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB, GaussianNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import issparse\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('text_preprocessing/final_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert sentiment labels to binary\n",
    "def convert_label_sentimen(label_sentimen):\n",
    "    return 1 if label_sentimen == \"positive\" else 0\n",
    "\n",
    "df['label_sentimen'] = df['Sentiment'].apply(convert_label_sentimen)\n",
    "df.drop(df.columns[[0]], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= df['tweet_tokens_stemmed'] \n",
    "y= df['label_sentimen']\n",
    "# k-fold cross-validation\n",
    "kfold = StratifiedKFold(n_splits=10, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes:\n",
    "    def __init__(self, model_class):\n",
    "        self.model_class = model_class\n",
    "        self.clf = None\n",
    "    \n",
    "    def fit(self, X_train, y_train, selected_features):\n",
    "        self.clf = self.model_class()\n",
    "        if issparse(X_train):\n",
    "            X_train = X_train.toarray()\n",
    "        self.clf.fit(X_train[:, selected_features], y_train)\n",
    "    \n",
    "    def predict(self, X_test, selected_features):\n",
    "        if self.clf is None:\n",
    "            raise ValueError(\"Classifier not fitted. Please call 'fit' method first.\")\n",
    "        if issparse(X_test):\n",
    "            X_test = X_test.toarray()\n",
    "        return self.clf.predict(X_test[:, selected_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_features(X_train, y_train, selected_features, classifier):\n",
    "    clf = classifier\n",
    "    cv_results = cross_val_score(clf.clf, X_train[:, selected_features], y_train, cv=kfold, scoring='accuracy')\n",
    "    return cv_results.mean()\n",
    "\n",
    "def pso_feature_selection(X_train, y_train, n_particles, inertia, global_weight, local_weight, model_class, tol=1e-5, patience=10):\n",
    "    num_samples, num_features = X_train.shape\n",
    "    bounds = [0, 1]\n",
    "    \n",
    "    num_particles = n_particles\n",
    "    dimensions = num_features\n",
    "    particles = np.random.rand(num_particles, dimensions)\n",
    "    velocities = np.random.rand(num_particles, dimensions) * 0.1\n",
    "    best_positions = particles.copy()\n",
    "    best_scores = np.zeros(num_particles)\n",
    "\n",
    "    global_best_position = np.zeros(dimensions)\n",
    "    global_best_score = 0\n",
    "\n",
    "    no_improvement_count = 0\n",
    "    previous_global_best_score = 0\n",
    "\n",
    "    while no_improvement_count < patience:\n",
    "        for particle in range(num_particles):\n",
    "            r1 = np.random.rand(dimensions)\n",
    "            r2 = np.random.rand(dimensions)\n",
    "            velocities[particle] = (inertia * velocities[particle] +\n",
    "                                    global_weight * r1 * (best_positions[particle] - particles[particle]) +\n",
    "                                    local_weight * r2 * (global_best_position - particles[particle]))\n",
    "\n",
    "            particles[particle] += velocities[particle]\n",
    "            particles[particle] = np.clip(particles[particle], bounds[0], bounds[1])\n",
    "\n",
    "            selected_features = particles[particle] > 0.5\n",
    "            nb = NaiveBayes(model_class)\n",
    "            nb.fit(X_train, y_train, selected_features)\n",
    "            accuracy = evaluate_features(X_train, y_train, selected_features, nb)\n",
    "\n",
    "            if accuracy > best_scores[particle]:\n",
    "                best_scores[particle] = accuracy\n",
    "                best_positions[particle] = particles[particle].copy()\n",
    "\n",
    "            if accuracy > global_best_score:\n",
    "                global_best_score = accuracy\n",
    "                global_best_position = particles[particle].copy()\n",
    "\n",
    "        if abs(global_best_score - previous_global_best_score) < tol:\n",
    "            no_improvement_count += 1\n",
    "        else:\n",
    "            no_improvement_count = 0\n",
    "        \n",
    "        previous_global_best_score = global_best_score\n",
    "\n",
    "    return global_best_position > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Population Size  Average Accuracy  Average Precision  Average Recall\n",
      "               5            0.7750           0.770596           0.795\n",
      "              10            0.7650           0.762314           0.785\n",
      "              20            0.7675           0.750758           0.810\n",
      "              40            0.7750           0.762815           0.825\n",
      "              80            0.7975           0.780576           0.835\n"
     ]
    }
   ],
   "source": [
    "# Define parameters for PSO optimization\n",
    "population_size_range = [5 * (2 ** i) for i in range(5)]  # 5, 10, 20\n",
    "inertia = 0.6\n",
    "global_weight = 0.3\n",
    "local_weight = 0.6\n",
    "\n",
    "results = []\n",
    "\n",
    "for n_particles in population_size_range:\n",
    "    accuracy_scores = []\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "\n",
    "    for train_idx, test_idx in kfold.split(X, y):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        tfidf_model = TfidfVectorizer(smooth_idf=False)\n",
    "        X_train_tfidf = tfidf_model.fit_transform(X_train)\n",
    "        X_test_tfidf = tfidf_model.transform(X_test)\n",
    "\n",
    "        X_train_dense = X_train_tfidf.toarray()\n",
    "        selected_features = pso_feature_selection(X_train_dense, y_train, n_particles, inertia, global_weight, local_weight, MultinomialNB)\n",
    "\n",
    "        if not np.any(selected_features):\n",
    "            selected_features[0] = True\n",
    "\n",
    "        nb = NaiveBayes(MultinomialNB)\n",
    "        nb.fit(X_train_tfidf, y_train, selected_features)\n",
    "        y_pred = nb.predict(X_test_tfidf.toarray(), selected_features)\n",
    "\n",
    "        accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
    "        precision_scores.append(precision_score(y_test, y_pred))\n",
    "        recall_scores.append(recall_score(y_test, y_pred))\n",
    "\n",
    "    fold_results = {\n",
    "        \"Population Size\": n_particles,\n",
    "        \"Average Accuracy\": np.mean(accuracy_scores),\n",
    "        \"Average Precision\": np.mean(precision_scores),\n",
    "        \"Average Recall\": np.mean(recall_scores)\n",
    "    }\n",
    "\n",
    "    results.append(fold_results)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values(by=[\"Population Size\", \"Average Accuracy\"], ascending=[True, False])\n",
    "\n",
    "print(results_df.to_string(index=False))\n",
    "results_df.to_csv(\"population_size.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Inertia Weight  Average Accuracy  Average Precision  Average Recall\n",
      "            0.1            0.7650           0.784097           0.755\n",
      "            0.2            0.7725           0.772463           0.780\n",
      "            0.3            0.7675           0.771691           0.775\n",
      "            0.4            0.7675           0.765741           0.785\n",
      "            0.5            0.7775           0.760949           0.825\n",
      "            0.6            0.7625           0.747992           0.800\n",
      "            0.7            0.7675           0.753645           0.805\n",
      "            0.8            0.7800           0.774077           0.800\n",
      "            0.9            0.7875           0.775102           0.810\n",
      "            1.0            0.7700           0.752978           0.805\n"
     ]
    }
   ],
   "source": [
    "# Define parameters for PSO optimization\n",
    "n_particles = 20\n",
    "inertia_weight_range = np.linspace(0.1, 1, num=10)\n",
    "global_weight = 0.3\n",
    "local_weight = 0.6\n",
    "\n",
    "results = []\n",
    "\n",
    "for inertia in inertia_weight_range:\n",
    "    accuracy_scores = []\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "\n",
    "    for train_idx, test_idx in kfold.split(X, y):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        tfidf_model = TfidfVectorizer(smooth_idf=False)\n",
    "        X_train_tfidf = tfidf_model.fit_transform(X_train)\n",
    "        X_test_tfidf = tfidf_model.transform(X_test)\n",
    "\n",
    "        X_train_dense = X_train_tfidf.toarray()\n",
    "        selected_features = pso_feature_selection(X_train_dense, y_train, n_particles, inertia, global_weight, local_weight, MultinomialNB)\n",
    "\n",
    "        if not np.any(selected_features):\n",
    "            selected_features[0] = True\n",
    "\n",
    "        nb = NaiveBayes(MultinomialNB)\n",
    "        nb.fit(X_train_tfidf, y_train, selected_features)\n",
    "        y_pred = nb.predict(X_test_tfidf.toarray(), selected_features)\n",
    "\n",
    "        accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
    "        precision_scores.append(precision_score(y_test, y_pred))\n",
    "        recall_scores.append(recall_score(y_test, y_pred))\n",
    "\n",
    "    fold_results = {\n",
    "        \"Inertia Weight\": inertia,\n",
    "        \"Average Accuracy\": np.mean(accuracy_scores),\n",
    "        \"Average Precision\": np.mean(precision_scores),\n",
    "        \"Average Recall\": np.mean(recall_scores)\n",
    "    }\n",
    "\n",
    "    results.append(fold_results)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values(by=[\"Inertia Weight\", \"Average Accuracy\"], ascending=[True, False])\n",
    "\n",
    "print(results_df.to_string(index=False))\n",
    "results_df.to_csv(\"inertia.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Global Best Weight  Average Accuracy  Average Precision  Average Recall\n",
      "                0.1            0.7900           0.760655           0.850\n",
      "                0.2            0.7925           0.783207           0.825\n",
      "                0.3            0.7875           0.762616           0.840\n",
      "                0.4            0.8150           0.796601           0.855\n",
      "                0.5            0.7850           0.781556           0.805\n",
      "                0.6            0.8000           0.797363           0.815\n",
      "                0.7            0.7900           0.793668           0.790\n",
      "                0.8            0.7800           0.774543           0.800\n",
      "                0.9            0.7875           0.777814           0.810\n",
      "                1.0            0.7775           0.767485           0.805\n"
     ]
    }
   ],
   "source": [
    "# Define parameters for PSO optimization\n",
    "n_particles = 20\n",
    "inertia = 0.8\n",
    "global_best_weight_range = np.linspace(0.1, 1, num=10)\n",
    "local_weight = 0.6\n",
    "\n",
    "results = []\n",
    "\n",
    "for global_weight in global_best_weight_range:\n",
    "    accuracy_scores = []\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "\n",
    "    for train_idx, test_idx in kfold.split(X, y):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        tfidf_model = TfidfVectorizer(smooth_idf=False)\n",
    "        X_train_tfidf = tfidf_model.fit_transform(X_train)\n",
    "        X_test_tfidf = tfidf_model.transform(X_test)\n",
    "\n",
    "        X_train_dense = X_train_tfidf.toarray()\n",
    "        selected_features = pso_feature_selection(X_train_dense, y_train, n_particles, inertia, global_weight, local_weight, MultinomialNB)\n",
    "\n",
    "        if not np.any(selected_features):\n",
    "            selected_features[0] = True\n",
    "\n",
    "        nb = NaiveBayes(MultinomialNB)\n",
    "        nb.fit(X_train_tfidf, y_train, selected_features)\n",
    "        y_pred = nb.predict(X_test_tfidf.toarray(), selected_features)\n",
    "\n",
    "        accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
    "        precision_scores.append(precision_score(y_test, y_pred))\n",
    "        recall_scores.append(recall_score(y_test, y_pred))\n",
    "\n",
    "    fold_results = {\n",
    "        \"Global Best Weight\": global_weight,\n",
    "        \"Average Accuracy\": np.mean(accuracy_scores),\n",
    "        \"Average Precision\": np.mean(precision_scores),\n",
    "        \"Average Recall\": np.mean(recall_scores)\n",
    "    }\n",
    "\n",
    "    results.append(fold_results)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values(by=[\"Global Best Weight\", \"Average Accuracy\"], ascending=[True, False])\n",
    "\n",
    "print(results_df.to_string(index=False))\n",
    "results_df.to_csv(\"global_weight.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Local Best Weight  Average Accuracy  Average Precision  Average Recall\n",
      "               0.1            0.7600           0.757244           0.795\n",
      "               0.2            0.7650           0.744899           0.810\n",
      "               0.3            0.7800           0.769116           0.805\n",
      "               0.4            0.7950           0.779661           0.830\n",
      "               0.5            0.7875           0.756655           0.850\n",
      "               0.6            0.7875           0.774852           0.820\n",
      "               0.7            0.7975           0.792216           0.815\n",
      "               0.8            0.7750           0.777189           0.785\n",
      "               0.9            0.7800           0.767367           0.805\n",
      "               1.0            0.7975           0.803686           0.795\n"
     ]
    }
   ],
   "source": [
    "# Define parameters for PSO optimization\n",
    "n_particles = 20\n",
    "inertia = 0.8\n",
    "global_weight = 1.0\n",
    "local_best_weight_range = np.linspace(0.1, 1, num=10)\n",
    "\n",
    "results = []\n",
    "\n",
    "for local_weight in local_best_weight_range:\n",
    "    accuracy_scores = []\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "\n",
    "    for train_idx, test_idx in kfold.split(X, y):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        tfidf_model = TfidfVectorizer(smooth_idf=False)\n",
    "        X_train_tfidf = tfidf_model.fit_transform(X_train)\n",
    "        X_test_tfidf = tfidf_model.transform(X_test)\n",
    "\n",
    "        X_train_dense = X_train_tfidf.toarray()\n",
    "        selected_features = pso_feature_selection(X_train_dense, y_train, n_particles, inertia, global_weight, local_weight, MultinomialNB)\n",
    "\n",
    "        if not np.any(selected_features):\n",
    "            selected_features[0] = True\n",
    "\n",
    "        nb = NaiveBayes(MultinomialNB)\n",
    "        nb.fit(X_train_tfidf, y_train, selected_features)\n",
    "        y_pred = nb.predict(X_test_tfidf.toarray(), selected_features)\n",
    "\n",
    "        accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
    "        precision_scores.append(precision_score(y_test, y_pred))\n",
    "        recall_scores.append(recall_score(y_test, y_pred))\n",
    "\n",
    "    fold_results = {\n",
    "        \"Local Best Weight\": local_weight,\n",
    "        \"Average Accuracy\": np.mean(accuracy_scores),\n",
    "        \"Average Precision\": np.mean(precision_scores),\n",
    "        \"Average Recall\": np.mean(recall_scores)\n",
    "    }\n",
    "\n",
    "    results.append(fold_results)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values(by=[\"Local Best Weight\", \"Average Accuracy\"], ascending=[True, False])\n",
    "\n",
    "print(results_df.to_string(index=False))\n",
    "results_df.to_csv(\"local_weight.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
